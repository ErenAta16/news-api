"""
Final RSS Veri ToplayÄ±cÄ± ModÃ¼lÃ¼

Bu modÃ¼l, dÃ¼zeltilmiÅŸ ve Ã§alÄ±ÅŸan RSS kaynaklarÄ±ndan
haber verilerini Ã§eker.
"""

import feedparser
import requests
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import logging

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FinalRSSCollector:
    """Final RSS akÄ±ÅŸlarÄ±ndan haber verilerini toplayan sÄ±nÄ±f"""
    
    def __init__(self):
        """RSS toplayÄ±cÄ±yÄ± baÅŸlat"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # Test edilmiÅŸ ve Ã§alÄ±ÅŸan RSS kaynaklarÄ±
        self.working_rss_sources = {
            'GÃ¼ndem': [
                "https://www.hurriyet.com.tr/rss/anasayfa",
                "https://www.aa.com.tr/tr/rss/default?cat=guncel",
                "https://www.bbc.com/turkce/index.xml"
            ],
            'Ekonomi': [
                "https://www.aa.com.tr/tr/rss/default?cat=ekonomi"
            ],
            'Spor': [
                "https://www.aa.com.tr/tr/rss/default?cat=spor"
            ],
            'DÃ¼nya': [
                "https://www.aa.com.tr/tr/rss/default?cat=dunya",
                "https://www.bbc.com/turkce/index.xml"
            ]
        }
        
        # Alternatif kaynaklar
        self.alternative_sources = [
            "https://feeds.bbci.co.uk/turkce/rss.xml",
            "https://www.hurriyet.com.tr/rss/anasayfa",
            "https://www.aa.com.tr/tr/rss/default?cat=guncel"
        ]
    
    def get_news_from_rss(self, rss_url: str, category: str = 'GÃ¼ndem') -> List[Dict]:
        """
        Belirtilen RSS URL'sinden haberleri Ã§eker
        
        Args:
            rss_url (str): RSS akÄ±ÅŸÄ±nÄ±n URL'si
            category (str): Haber kategorisi
            
        Returns:
            List[Dict]: Haber verilerinin listesi
        """
        try:
            logger.info(f"RSS akÄ±ÅŸÄ±ndan veri Ã§ekiliyor: {rss_url}")
            
            # Timeout olmadan RSS akÄ±ÅŸÄ±nÄ± parse et
            feed = feedparser.parse(rss_url)
            
            if feed.bozo:
                logger.warning(f"RSS akÄ±ÅŸÄ±nda hata var: {rss_url}")
            
            news_list = []
            
            for entry in feed.entries:
                # Tarih kontrolÃ¼ yapmadan tÃ¼m haberleri al
                published_date = self._parse_date(entry.get('published', ''))
                
                news_item = {
                    'title': entry.get('title', ''),
                    'summary': entry.get('summary', ''),
                    'link': entry.get('link', ''),
                    'published': published_date or datetime.now().isoformat(),
                    'source': rss_url,
                    'category': category,
                    'collected_at': datetime.now().isoformat(),
                    'source_name': self._extract_source_name(rss_url)
                }
                news_list.append(news_item)
            
            logger.info(f"{len(news_list)} haber Ã§ekildi: {rss_url}")
            return news_list
            
        except Exception as e:
            logger.error(f"RSS akÄ±ÅŸÄ±ndan veri Ã§ekilirken hata: {rss_url}, Hata: {str(e)}")
            return []
    
    def _parse_date(self, date_str: str) -> Optional[str]:
        """
        Tarih string'ini ISO formatÄ±na Ã§evirir
        
        Args:
            date_str (str): Tarih string'i
            
        Returns:
            Optional[str]: ISO formatÄ±nda tarih veya None
        """
        if not date_str:
            return None
        
        try:
            # feedparser'Ä±n tarih parse etme Ã¶zelliÄŸini kullan
            parsed_date = feedparser._parse_date(date_str)
            if parsed_date:
                return parsed_date.isoformat()
        except:
            pass
        
        return None
    
    def _extract_source_name(self, url: str) -> str:
        """
        URL'den kaynak adÄ±nÄ± Ã§Ä±karÄ±r
        
        Args:
            url (str): RSS URL'si
            
        Returns:
            str: Kaynak adÄ±
        """
        if 'hurriyet' in url:
            return 'HÃ¼rriyet'
        elif 'aa.com.tr' in url:
            return 'Anadolu AjansÄ±'
        elif 'bbc.com' in url or 'bbci.co.uk' in url:
            return 'BBC TÃ¼rkÃ§e'
        elif 'cnnturk' in url:
            return 'CNN TÃ¼rk'
        elif 'ntv.com.tr' in url:
            return 'NTV'
        elif 'trthaber' in url:
            return 'TRT Haber'
        elif 'anadolu.com.tr' in url:
            return 'Anadolu'
        elif 'milliyet' in url:
            return 'Milliyet'
        else:
            return 'DiÄŸer'
    
    async def collect_from_category(self, category: str) -> List[Dict]:
        """
        Belirli bir kategoriden haber toplar
        
        Args:
            category (str): Haber kategorisi
            
        Returns:
            List[Dict]: Kategoriden toplanan haberler
        """
        if category not in self.working_rss_sources:
            logger.warning(f"Bilinmeyen kategori: {category}")
            return []
        
        urls = self.working_rss_sources[category]
        all_news = []
        
        for url in urls:
            try:
                news = self.get_news_from_rss(url, category)
                all_news.extend(news)
                # Rate limiting
                await asyncio.sleep(2)
            except Exception as e:
                logger.error(f"{url} kaynaÄŸÄ±ndan veri Ã§ekilemedi: {e}")
        
        logger.info(f"{category} kategorisinden {len(all_news)} haber toplandÄ±")
        return all_news
    
    async def collect_all_feeds(self) -> List[Dict]:
        """
        TÃ¼m RSS kaynaklarÄ±ndan haberleri toplar
        
        Returns:
            List[Dict]: TÃ¼m kaynaklardan toplanan haberler
        """
        logger.info("TÃ¼m RSS kaynaklarÄ±ndan veri toplanÄ±yor...")
        
        all_news = []
        
        # Kategorilere gÃ¶re toplama
        for category in self.working_rss_sources.keys():
            try:
                news = await self.collect_from_category(category)
                all_news.extend(news)
            except Exception as e:
                logger.error(f"{category} kategorisi toplanamadÄ±: {e}")
        
        # EÄŸer hiÃ§ haber toplanamadÄ±ysa alternatif kaynaklarÄ± dene
        if not all_news:
            logger.info("Ana kaynaklardan veri toplanamadÄ±, alternatif kaynaklar deneniyor...")
            for url in self.alternative_sources:
                try:
                    news = self.get_news_from_rss(url, 'GÃ¼ndem')
                    all_news.extend(news)
                    if news:
                        logger.info(f"Alternatif kaynaktan {len(news)} haber toplandÄ±: {url}")
                except Exception as e:
                    logger.error(f"Alternatif kaynak hatasÄ±: {url}, {e}")
        
        # Duplicate haberleri temizle
        unique_news = self._remove_duplicates(all_news)
        
        logger.info(f"Toplam {len(unique_news)} benzersiz haber toplandÄ±")
        return unique_news
    
    def _remove_duplicates(self, news_list: List[Dict]) -> List[Dict]:
        """
        Duplicate haberleri temizler
        
        Args:
            news_list (List[Dict]): Haber listesi
            
        Returns:
            List[Dict]: Benzersiz haberler
        """
        seen_titles = set()
        unique_news = []
        
        for news in news_list:
            # BaÅŸlÄ±ÄŸÄ± normalize et
            title = news['title'].lower().strip()
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_news.append(news)
        
        return unique_news
    
    def get_statistics(self, news_list: List[Dict]) -> Dict:
        """
        Haber istatistiklerini hesaplar
        
        Args:
            news_list (List[Dict]): Haber listesi
            
        Returns:
            Dict: Ä°statistikler
        """
        if not news_list:
            return {
                'total_news': 0,
                'category_distribution': {},
                'source_distribution': {},
                'collection_time': datetime.now().isoformat()
            }
        
        # Kategori daÄŸÄ±lÄ±mÄ±
        category_counts = {}
        source_counts = {}
        
        for news in news_list:
            category = news.get('category', 'bilinmeyen')
            source = news.get('source_name', 'bilinmeyen')
            
            category_counts[category] = category_counts.get(category, 0) + 1
            source_counts[source] = source_counts.get(source, 0) + 1
        
        return {
            'total_news': len(news_list),
            'category_distribution': category_counts,
            'source_distribution': source_counts,
            'collection_time': datetime.now().isoformat()
        }

# Test iÃ§in Ã¶rnek kullanÄ±m
async def test_final_collector():
    """Final toplayÄ±cÄ±yÄ± test et"""
    collector = FinalRSSCollector()
    
    print("ğŸ” Final RSS ToplayÄ±cÄ± Test Ediliyor...")
    print("=" * 60)
    
    # TÃ¼m kategorilerden veri topla
    all_news = await collector.collect_all_feeds()
    
    # Ä°statistikleri gÃ¶ster
    stats = collector.get_statistics(all_news)
    
    print(f"\nğŸ“Š TOPLAMA Ä°STATÄ°STÄ°KLERÄ°:")
    print(f"  Toplam haber: {stats['total_news']}")
    print(f"  Toplama zamanÄ±: {stats['collection_time']}")
    
    print(f"\nğŸ·ï¸ KATEGORÄ° DAÄILIMI:")
    for category, count in stats['category_distribution'].items():
        print(f"  {category}: {count} haber")
    
    print(f"\nğŸ“¡ KAYNAK DAÄILIMI:")
    for source, count in stats['source_distribution'].items():
        print(f"  {source}: {count} haber")
    
    # Ã–rnek haberler gÃ¶ster
    if all_news:
        print(f"\nğŸ“° Ã–RNEK HABERLER:")
        for i, news in enumerate(all_news[:5], 1):
            print(f"  {i}. {news['title']}")
            print(f"     Kategori: {news['category']}")
            print(f"     Kaynak: {news['source_name']}")
            print(f"     Tarih: {news['published']}")
            print()
    else:
        print("\nâŒ HiÃ§ haber toplanamadÄ±!")

if __name__ == "__main__":
    asyncio.run(test_final_collector()) 