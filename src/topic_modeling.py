"""
Konu Modelleme ModÃ¼lÃ¼

Bu modÃ¼l, haber metinlerini LDA (Latent Dirichlet Allocation) kullanarak
otomatik olarak konulara/kategorilere ayÄ±rÄ±r.
"""

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.decomposition import NMF
from typing import List, Dict, Tuple
import pandas as pd
import logging

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TopicModeler:
    """LDA ve NMF kullanarak konu modelleme yapan sÄ±nÄ±f"""
    
    def __init__(self, n_topics: int = 5, method: str = 'lda'):
        """
        Konu modelleyiciyi baÅŸlat
        
        Args:
            n_topics (int): OluÅŸturulacak konu sayÄ±sÄ±
            method (str): 'lda' veya 'nmf' kullanÄ±lacak yÃ¶ntem
        """
        self.n_topics = n_topics
        self.method = method
        self.vectorizer = None
        self.model = None
        self.feature_names = None
        
    def prepare_data(self, texts: List[str], max_features: int = 1000):
        """
        Metinleri TF-IDF vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
        
        Args:
            texts (List[str]): TemizlenmiÅŸ metinlerin listesi
            max_features (int): Maksimum Ã¶zellik sayÄ±sÄ±
        """
        logger.info("Metinler TF-IDF vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
        
        self.vectorizer = TfidfVectorizer(
            max_features=max_features,
            stop_words=None,  # Zaten temizlenmiÅŸ metinler
            min_df=2,  # En az 2 dokÃ¼manda geÃ§en kelimeler
            max_df=0.95  # %95'ten fazla dokÃ¼manda geÃ§en kelimeleri Ã§Ä±kar
        )
        
        # TF-IDF matrisini oluÅŸtur
        tfidf_matrix = self.vectorizer.fit_transform(texts)
        self.feature_names = self.vectorizer.get_feature_names_out()
        
        logger.info(f"TF-IDF matrisi oluÅŸturuldu: {tfidf_matrix.shape}")
        return tfidf_matrix
    
    def fit_model(self, tfidf_matrix):
        """
        Konu modelini eÄŸitir
        
        Args:
            tfidf_matrix: TF-IDF matrisi
        """
        logger.info(f"{self.method.upper()} konu modeli eÄŸitiliyor...")
        
        if self.method == 'lda':
            self.model = LatentDirichletAllocation(
                n_components=self.n_topics,
                random_state=42,
                max_iter=20,
                learning_method='batch'
            )
        elif self.method == 'nmf':
            self.model = NMF(
                n_components=self.n_topics,
                random_state=42,
                max_iter=200
            )
        else:
            raise ValueError("Method must be 'lda' or 'nmf'")
        
        # Modeli eÄŸit
        self.model.fit(tfidf_matrix)
        logger.info("Konu modeli eÄŸitimi tamamlandÄ±")
    
    def get_topics(self, n_words: int = 10) -> List[List[Tuple[str, float]]]:
        """
        Her konu iÃ§in en Ã¶nemli kelimeleri dÃ¶ndÃ¼rÃ¼r
        
        Args:
            n_words (int): Her konu iÃ§in dÃ¶ndÃ¼rÃ¼lecek kelime sayÄ±sÄ±
            
        Returns:
            List[List[Tuple[str, float]]]: Her konu iÃ§in (kelime, aÄŸÄ±rlÄ±k) listesi
        """
        if self.model is None:
            raise ValueError("Model henÃ¼z eÄŸitilmemiÅŸ")
        
        topics = []
        feature_names = self.vectorizer.get_feature_names_out()
        
        for topic_idx, topic in enumerate(self.model.components_):
            # En yÃ¼ksek aÄŸÄ±rlÄ±klÄ± kelimeleri al
            top_words_idx = topic.argsort()[:-n_words-1:-1]
            top_words = [(feature_names[i], topic[i]) for i in top_words_idx]
            topics.append(top_words)
        
        return topics
    
    def assign_topics_to_documents(self, texts: List[str]) -> List[int]:
        """
        Her dokÃ¼mana en uygun konuyu atar
        
        Args:
            texts (List[str]): DokÃ¼man metinleri
            
        Returns:
            List[int]: Her dokÃ¼man iÃ§in atanan konu indeksi
        """
        if self.model is None or self.vectorizer is None:
            raise ValueError("Model henÃ¼z eÄŸitilmemiÅŸ")
        
        # DokÃ¼manlarÄ± vektÃ¶rize et
        tfidf_matrix = self.vectorizer.transform(texts)
        
        # Konu daÄŸÄ±lÄ±mlarÄ±nÄ± hesapla
        topic_distributions = self.model.transform(tfidf_matrix)
        
        # En yÃ¼ksek olasÄ±lÄ±klÄ± konuyu seÃ§
        assigned_topics = topic_distributions.argmax(axis=1)
        
        return assigned_topics.tolist()
    
    def model_topics(self, texts: List[str]) -> Dict:
        """
        Konu modelleme yapar
        
        Args:
            texts (List[str]): TemizlenmiÅŸ metinlerin listesi
            
        Returns:
            Dict: Konu modelleme sonuÃ§larÄ±
        """
        logger.info("Konu modelleme baÅŸlatÄ±lÄ±yor...")
        
        if len(texts) < 2:
            logger.warning("Yetersiz metin sayÄ±sÄ±, konu modelleme yapÄ±lamÄ±yor")
            return {
                'topics': [],
                'topic_counts': {},
                'assigned_topics': [],
                'method': self.method,
                'n_topics': 0
            }
        
        try:
            # Veriyi hazÄ±rla
            tfidf_matrix = self.prepare_data(texts)
            
            # Modeli eÄŸit
            self.fit_model(tfidf_matrix)
            
            # KonularÄ± al
            topics = self.get_topics()
            
            # DokÃ¼manlara konu ata
            assigned_topics = self.assign_topics_to_documents(texts)
            
            # Konu daÄŸÄ±lÄ±mÄ±nÄ± hesapla
            topic_counts = pd.Series(assigned_topics).value_counts().to_dict()
            
            results = {
                'topics': topics,
                'topic_counts': topic_counts,
                'assigned_topics': assigned_topics,
                'method': self.method,
                'n_topics': self.n_topics,
                'total_documents': len(texts)
            }
            
            logger.info("Konu modelleme tamamlandÄ±")
            return results
            
        except Exception as e:
            logger.error(f"Konu modelleme hatasÄ±: {e}")
            return {
                'topics': [],
                'topic_counts': {},
                'assigned_topics': [],
                'method': self.method,
                'n_topics': 0,
                'error': str(e)
            }
    
    def analyze_topics(self, texts: List[str], news_items: List[Dict]) -> Dict:
        """
        Konu analizi yapar ve sonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r
        
        Args:
            texts (List[str]): TemizlenmiÅŸ metinler
            news_items (List[Dict]): Orijinal haber verileri
            
        Returns:
            Dict: Analiz sonuÃ§larÄ±
        """
        logger.info("Konu analizi baÅŸlatÄ±lÄ±yor...")
        
        # Veriyi hazÄ±rla
        tfidf_matrix = self.prepare_data(texts)
        
        # Modeli eÄŸit
        self.fit_model(tfidf_matrix)
        
        # KonularÄ± al
        topics = self.get_topics()
        
        # DokÃ¼manlara konu ata
        assigned_topics = self.assign_topics_to_documents(texts)
        
        # Konu daÄŸÄ±lÄ±mÄ±nÄ± hesapla
        topic_counts = pd.Series(assigned_topics).value_counts().to_dict()
        
        # Her konu iÃ§in Ã¶rnek haberler
        topic_examples = {}
        for topic_idx in range(self.n_topics):
            topic_news = [news_items[i] for i, assigned in enumerate(assigned_topics) if assigned == topic_idx]
            topic_examples[topic_idx] = topic_news[:3]  # Ä°lk 3 Ã¶rnek
        
        results = {
            'topics': topics,
            'topic_counts': topic_counts,
            'assigned_topics': assigned_topics,
            'topic_examples': topic_examples,
            'method': self.method,
            'n_topics': self.n_topics
        }
        
        logger.info("Konu analizi tamamlandÄ±")
        return results
    
    def print_topic_summary(self, results: Dict):
        """
        Konu analizi sonuÃ§larÄ±nÄ± yazdÄ±rÄ±r
        """
        print(f"\n=== {results['method'].upper()} Konu Analizi SonuÃ§larÄ± ===")
        print(f"Toplam Konu SayÄ±sÄ±: {results['n_topics']}")
        
        print("\nğŸ“Š Konu DaÄŸÄ±lÄ±mÄ±:")
        for topic_idx, count in results['topic_counts'].items():
            print(f"Konu {topic_idx}: {count} haber")
        
        print("\nğŸ·ï¸ Konu Ä°Ã§erikleri:")
        for topic_idx, topic_words in enumerate(results['topics']):
            print(f"\nKonu {topic_idx}:")
            words_str = ", ".join([f"{word} ({weight:.3f})" for word, weight in topic_words[:5]])
            print(f"  Anahtar kelimeler: {words_str}")
            
            # Ã–rnek haberler
            if topic_idx in results['topic_examples']:
                examples = results['topic_examples'][topic_idx]
                print(f"  Ã–rnek haberler:")
                for i, example in enumerate(examples, 1):
                    title = example.get('title', '')[:60]
                    print(f"    {i}. {title}...")

# Test iÃ§in Ã¶rnek kullanÄ±m
if __name__ == "__main__":
    # Ã–rnek metinler
    sample_texts = [
        "ekonomi bÃ¼yÃ¼me hedef revize edildi bakan aÃ§Ä±klama",
        "bakan ekonomi bÃ¼yÃ¼me aÃ§Ä±klama yaptÄ±",
        "bÃ¼yÃ¼me hedef ekonomi 2024",
        "siyaset cumhurbaÅŸkanÄ± toplantÄ± karar",
        "cumhurbaÅŸkanÄ± siyaset karar aldÄ±",
        "spor futbol maÃ§ sonuÃ§ galibiyet",
        "futbol spor maÃ§ sonuÃ§",
        "hava durumu sÄ±caklÄ±k yaÄŸÄ±ÅŸ",
        "sÄ±caklÄ±k hava durumu artÄ±ÅŸ"
    ]
    
    # LDA konu modelleme
    lda_modeler = TopicModeler(n_topics=3, method='lda')
    lda_results = lda_modeler.model_topics(sample_texts)
    
    print("LDA Konu Modelleme SonuÃ§larÄ±:")
    print(lda_results)
    
    # NMF konu modelleme
    nmf_modeler = TopicModeler(n_topics=3, method='nmf')
    nmf_results = nmf_modeler.model_topics(sample_texts)
    
    print("\nNMF Konu Modelleme SonuÃ§larÄ±:")
    print(nmf_results) 